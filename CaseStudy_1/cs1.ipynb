{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9becd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "\n",
    "# Import the first CSV file\n",
    "df1 = pd.read_csv('../Datasets/superconduct/train.csv')\n",
    "\n",
    "# Import the second CSV file\n",
    "df2 = pd.read_csv('../Datasets/superconduct/unique_m.csv')\n",
    "df2 = df2.drop(['critical_temp', 'material'], axis=1)\n",
    "\n",
    "combined_df = df1.join(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863df28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41fb8073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results[\"rank_test_score\"] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\n",
    "                \"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                    results[\"mean_test_score\"][candidate],\n",
    "                    results[\"std_test_score\"][candidate],\n",
    "                )\n",
    "            )\n",
    "            print(\"Parameters: {0}\".format(results[\"params\"][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b7682e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xclusive/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/xclusive/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/xclusive/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.941e+06, tolerance: 1.686e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/xclusive/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/xclusive/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/xclusive/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.979e+06, tolerance: 1.759e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/xclusive/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/xclusive/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/xclusive/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.444e+06, tolerance: 2.056e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/xclusive/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/xclusive/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/xclusive/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.694e+06, tolerance: 2.085e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/xclusive/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:680: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/home/xclusive/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/xclusive/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.502e+06, tolerance: 2.134e+03 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/xclusive/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.440e+05, tolerance: 1.686e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/xclusive/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.358e+05, tolerance: 1.759e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/xclusive/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.906e+05, tolerance: 2.056e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/xclusive/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.181e+05, tolerance: 2.085e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/xclusive/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.841e+05, tolerance: 2.134e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_236369/1684543606.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m }\n\u001b[1;32m     17\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#neg_mean_absolute_error suggested 0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    836\u001b[0m                     )\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1037\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                 \u001b[0mthis_Xy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m             _, this_coef, this_dual_gap, this_iter = self.path(\n\u001b[0m\u001b[1;32m   1040\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36menet_path\u001b[0;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[1;32m    645\u001b[0m             )\n\u001b[1;32m    646\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mprecompute\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m             model = cd_fast.enet_coordinate_descent(\n\u001b[0m\u001b[1;32m    648\u001b[0m                 \u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m             )\n",
      "\u001b[0;32msklearn/linear_model/_cd_fast.pyx\u001b[0m in \u001b[0;36msklearn.linear_model._cd_fast.enet_coordinate_descent\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/numpy/core/getlimits.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumeric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create train/test split\n",
    "# Split the data into X and y\n",
    "X = combined_df.drop('critical_temp', axis=1)\n",
    "y = combined_df['critical_temp']\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    " # Add column names back into the scaled X_train data frame\n",
    "X_scaled = pd.DataFrame(data=X_scaled, columns=X.columns)\n",
    "\n",
    "model = Lasso()\n",
    "param_dist = {\n",
    "    \"alpha\": np.arange(0, 1.01, 0.01)    #np.arange(0, 5.0, 0.01) for neg_absolute_error\n",
    "}\n",
    "grid_search = GridSearchCV(model, param_grid=param_dist, scoring='r2', cv=5) #neg_mean_absolute_error suggested 0.01\n",
    "grid_search.fit(X_scaled, y)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "#report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60462364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "vi = []\n",
    "for i in np.arange(0, 1.01, 0.01):\n",
    "    model.alpha = i\n",
    "    model.fit(X_scaled,y)\n",
    "    vi.append(model.coef_)\n",
    "\n",
    "# Plot the coefficients\n",
    "V=pd.DataFrame(np.array(vi),columns=X_scaled.columns)\n",
    "for i in V.columns:\n",
    "    plt.plot(np.arange(0, 1.01, 0.01),V[i],label=i)\n",
    "\n",
    "plt.plot(np.arange(0, 1.01, 0.01), vi)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('Convergence of Lasso Coefficients')\n",
    "#plt.legend()\n",
    "plt.show()\n",
    "    \n",
    "    \n",
    "#V=pd.DataFrame(np.array(vi),columns=X_scaled.columns)\n",
    "#import matplotlib.pyplot as plt\n",
    "#for i in V.columns:\n",
    "#    plt.plot(np.arange(0, 5.0, 0.01),V[i],label=i)\n",
    "#plt.plot(np.ones(100)*.002,np.linspace(-1,1,100))\n",
    "#plt.xscale('linear')\n",
    "#plt.legend()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a700a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Add column names back into the scaled X_train data frame\n",
    "X_scaled = pd.DataFrame(data=X_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fface37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Lasso regressor\n",
    "l1_model = Lasso(alpha=.35)               #r2 metric from gridsearch said .35 was the best alpha between 0-1. neg_mean_absolute_error\n",
    "\n",
    "# Fit the regressor to the data\n",
    "l1_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = l1_model.predict(X_test)\n",
    "\n",
    "# Compute the MSE of the Lasso model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error: \", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b1e4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_coef = []\n",
    "for i in range(len(X_scaled.columns)):\n",
    "    if l1_model.coef_[i] != 0:\n",
    "        non_zero_coef.append((X_scaled.columns[i], abs(l1_model.coef_[i])))\n",
    "print(sorted(non_zero_coef, key=lambda x:x[1], reverse = True))\n",
    "\n",
    "print(len(non_zero_coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29f0a0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best regularization strength:  {'alpha': 2976.3514416313133}\n",
      "Best mean squared error:  376.0095670559369\n"
     ]
    }
   ],
   "source": [
    "# Create train/test split\n",
    "# Split the data into X and y\n",
    "X = combined_df.drop('critical_temp', axis=1)\n",
    "y = combined_df['critical_temp']\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    " # Add column names back into the scaled X_train data frame\n",
    "X_scaled = pd.DataFrame(data=X_scaled, columns=X.columns)\n",
    "\n",
    "model = Ridge()\n",
    "param_dist = {\n",
    "    'alpha': np.logspace(-6, 6, 10)\n",
    "}\n",
    "grid_search = GridSearchCV(model, param_grid=param_dist, scoring='neg_mean_squared_error', cv=5) #neg_mean_absolute_error suggested 0.01\n",
    "grid_search.fit(X_scaled, y)\n",
    "\n",
    "print(\"Best regularization strength: \", grid_search.best_params_)\n",
    "print(\"Best mean squared error: \", -grid_search.best_score_)\n",
    "\n",
    "ridge_alpha = grid_search.best_params_\n",
    "#report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b12af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "vi = []\n",
    "for i in np.logspace(-6, 6, 10):\n",
    "    model.alpha = i\n",
    "    model.fit(X_scaled,y)\n",
    "    vi.append(model.coef_)\n",
    "\n",
    "# Plot the coefficients\n",
    "V=pd.DataFrame(np.array(vi),columns=X_scaled.columns)\n",
    "for i in V.columns:\n",
    "    plt.plot(np.logspace(-6, 6, 10),V[i],label=i)\n",
    "\n",
    "plt.plot(np.logspace(-6, 6, 10), vi)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('Convergence of Lasso Coefficients')\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48d080e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Add column names back into the scaled X_train data frame\n",
    "X_scaled = pd.DataFrame(data=X_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dad2b23a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ridge_alpha' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_236369/1969148939.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Instantiate a Lasso regressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ml2_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mridge_alpha\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alpha'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m               \u001b[0;31m#r2 metric from gridsearch said .35 was the best alpha between 0-1. neg_mean_absolute_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Fit the regressor to the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ml2_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ridge_alpha' is not defined"
     ]
    }
   ],
   "source": [
    "# Instantiate a Lasso regressor\n",
    "l2_model = Ridge(alpha=ridge_alpha['alpha'])               #r2 metric from gridsearch said .35 was the best alpha between 0-1. neg_mean_absolute_error\n",
    "\n",
    "# Fit the regressor to the data\n",
    "l2_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = l2_model.predict(X_test)\n",
    "\n",
    "# Compute the MSE of the Lasso model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error: \", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd13420b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('wtd_entropy_Valence', 35.7126281920486), ('wtd_entropy_fie', 25.483936903563606), ('wtd_entropy_FusionHeat', 19.990256436286256), ('entropy_atomic_mass', 16.269318832668564), ('wtd_std_Valence', 15.930976186210946), ('entropy_Valence', 15.427375791278797), ('wtd_entropy_ElectronAffinity', 15.340129796486115), ('entropy_FusionHeat', 15.336386733809487), ('entropy_ThermalConductivity', 13.01622950100774), ('Ag', 11.450766314936418), ('F', 8.67201988053719), ('wtd_entropy_atomic_radius', 8.418845433272086), ('Ba', 7.660216626626173), ('Rb', 7.5141472893618415), ('K', 7.1945507806237625), ('entropy_ElectronAffinity', 6.990190974842229), ('Hg', 6.972053577814011), ('entropy_fie', 6.5581017653692095), ('wtd_entropy_atomic_mass', 6.339183258287006), ('Cl', 6.161781739351226), ('I', 6.0951449395458805), ('gmean_Valence', 6.027546475954805), ('Bi', 5.984227893744472), ('entropy_Density', 5.863701368641587), ('range_Valence', 5.499786923885246), ('Na', 5.1129113808222), ('mean_Valence', 5.071609784016324), ('Tl', 5.071486128805807), ('Pt', 3.949761896532965), ('std_Valence', 3.8107828252662594), ('Lu', 3.5489272543208448), ('Li', 3.548389297636809), ('wtd_entropy_Density', 3.3155737805425614), ('Dy', 3.2051502646158085), ('Cs', 3.1967314718500024), ('Yb', 3.1527888476783104), ('Ho', 2.7760606962386234), ('Ce', 2.5746614949797997), ('wtd_gmean_Valence', 2.1873140312718324), ('Nd', 1.97063012208491), ('wtd_mean_Valence', 1.888108751182919), ('Er', 1.8740365326140955), ('wtd_mean_atomic_radius', 1.7908896313768352), ('Tc', 1.7003769819716015), ('As', 1.6817987876516645), ('wtd_mean_FusionHeat', 1.660852603492033), ('wtd_gmean_atomic_radius', 1.515660343238204), ('S', 1.5147163605050764), ('P', 1.504179464683346), ('Pb', 1.419915261462972), ('Fe', 1.3921275804873507), ('Si', 1.3895698179545557), ('entropy_atomic_radius', 1.3529729840606923), ('Tm', 1.3293457560165607), ('Ca', 1.3078887974585578), ('mean_FusionHeat', 1.2520952485105368), ('Eu', 1.2446734368734977), ('In', 1.2084523911800737), ('Os', 1.1653167570453289), ('wtd_gmean_FusionHeat', 1.1637264145582196), ('wtd_entropy_ThermalConductivity', 1.1609891258648206), ('wtd_mean_atomic_mass', 1.154276455203512), ('std_ElectronAffinity', 1.1375788232457849), ('Hf', 1.067181846449281), ('Tb', 1.0533360608413447), ('Se', 1.0008356651529544), ('Ge', 0.9683952932412427), ('Gd', 0.9032168281399706), ('gmean_FusionHeat', 0.8549449367133731), ('mean_atomic_mass', 0.8422431863302055), ('number_of_elements', 0.804138314208557), ('Y', 0.7786359016714737), ('std_FusionHeat', 0.7447849100975192), ('Au', 0.7332395614906226), ('wtd_gmean_atomic_mass', 0.6783787065143301), ('W', 0.6657937015216515), ('Sm', 0.6496307071195855), ('wtd_std_FusionHeat', 0.6493353840942875), ('wtd_range_FusionHeat', 0.5676143970050941), ('wtd_std_ElectronAffinity', 0.5012988371994881), ('std_atomic_mass', 0.49555167517428816), ('Cu', 0.49101183290281913), ('mean_atomic_radius', 0.4884179567750736), ('wtd_mean_ThermalConductivity', 0.48815407482734935), ('wtd_gmean_ElectronAffinity', 0.48267077109382633), ('Mn', 0.4764973287310513), ('Co', 0.4594102441648835), ('gmean_atomic_mass', 0.42663575942556436), ('Cr', 0.4245487064317511), ('wtd_mean_ElectronAffinity', 0.405887607115994), ('N', 0.38475404593674317), ('Ga', 0.36672089226801524), ('range_ElectronAffinity', 0.3276741618212848), ('wtd_gmean_ThermalConductivity', 0.3203360266450698), ('std_ThermalConductivity', 0.3194289446435624), ('B', 0.30556276575421776), ('Zn', 0.3054990939674413), ('O', 0.30178631410631496), ('std_atomic_radius', 0.29097497449811827), ('Ni', 0.2863211646700084), ('Sr', 0.2724304212350081), ('wtd_range_Valence', 0.2543000342641634), ('Ru', 0.2502247011336458), ('Sb', 0.2382844613747393), ('gmean_atomic_radius', 0.23317595236344626), ('Sc', 0.2071002545307697), ('wtd_range_ThermalConductivity', 0.20219125561069293), ('range_atomic_mass', 0.1926253319010398), ('range_FusionHeat', 0.15371411492858797), ('Pd', 0.1459678733440001), ('gmean_ElectronAffinity', 0.14289058999424942), ('Be', 0.12961143821955728), ('Te', 0.12833503244832606), ('wtd_range_atomic_mass', 0.11475370920483824), ('std_fie', 0.11439895269278816), ('Rh', 0.1123092851702613), ('Al', 0.11183892579974641), ('range_ThermalConductivity', 0.10567434062992356), ('wtd_range_atomic_radius', 0.09133106341608191), ('mean_ThermalConductivity', 0.08911280351784956), ('Cd', 0.08468013369920989), ('Nb', 0.08233138823047456), ('Re', 0.08223207783929468), ('Mo', 0.08202060696826853), ('Ir', 0.07820759595558015), ('mean_fie', 0.07807025919353042), ('mean_ElectronAffinity', 0.0780394513805495), ('wtd_range_ElectronAffinity', 0.07643973099905219), ('wtd_gmean_fie', 0.07385297134637366), ('Ti', 0.07067632306739116), ('gmean_fie', 0.06245345981808564), ('range_atomic_radius', 0.06231409293932143), ('Pr', 0.061347733569309545), ('V', 0.0551796977408238), ('range_fie', 0.04948602849679), ('Sn', 0.04912015322836166), ('Mg', 0.04552191827270678), ('wtd_std_atomic_mass', 0.043684841667521464), ('wtd_std_ThermalConductivity', 0.040458943210662374), ('gmean_ThermalConductivity', 0.03974419187374045), ('wtd_mean_fie', 0.03868360765799822), ('Br', 0.03485782718605621), ('C', 0.023718631466880104), ('H', 0.02291923816767431), ('wtd_std_atomic_radius', 0.022666114634307385), ('Ta', 0.01909262320424293), ('wtd_std_fie', 0.018171747560522207), ('wtd_range_fie', 0.01194385747158549), ('Zr', 0.005607902648601138), ('mean_Density', 0.005281089749959635), ('wtd_mean_Density', 0.004534577174730907), ('std_Density', 0.004194853061894055), ('La', 0.001963543828609), ('wtd_std_Density', 0.0014731304282524324), ('range_Density', 0.0011706638141250301), ('gmean_Density', 0.0007461417793911727), ('wtd_range_Density', 0.0007261889268763932), ('wtd_gmean_Density', 0.00036541775009693036)]\n",
      "158\n"
     ]
    }
   ],
   "source": [
    "non_zero_coef = []\n",
    "for i in range(len(X_scaled.columns)):\n",
    "    if l2_model.coef_[i] != 0:\n",
    "        non_zero_coef.append((X_scaled.columns[i], abs(l2_model.coef_[i])))\n",
    "print(sorted(non_zero_coef, key=lambda x:x[1], reverse = True))\n",
    "\n",
    "print(len(non_zero_coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c05ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa04f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f04e5f75e44efcd353fef4603716093c577a3d826b125371c00a8307ebe4216f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
